---
date: 2025-05-22
hora: 10:47
tags:
---
2025-05-22 10:45:38,930 - INFO - Best threshold=0.47 yields DirAcc(clf)=0.5922
2025-05-22 10:39:59,554 - INFO - Reg — MAE: 0.0031 RMSE: 0.0046 Corr: 0.3583 DirAcc: 0.5815
![[Pasted image 20250522104754.png]]

# Coisas
- [ ] Academia
- [ ] Tomar remédio
- [ ] Tomar Creatina


# 4.2_hpo.py
# Dependency check
import sys
print(sys.executable)
required_packages = [
    'pandas', 'numpy', 'sklearn', 'scipy', 'xgboost', 'joblib', 'matplotlib',
    'fastapi', 'uvicorn', 'pydantic'
]
missing = []
for pkg in required_packages:
    try:
        __import__(pkg)
    except ImportError:
        missing.append(pkg)
if missing:
    install_cmd = f"{sys.executable} -m pip install " + " ".join(missing)
    print("Missing packages: " + ", ".join(missing))
    print("Please install them via the same Python used to run this script:")
    print(install_cmd)
    sys.exit(1)

import os
import logging
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, make_scorer
from sklearn.calibration import CalibratedClassifierCV
from xgboost import XGBClassifier
import xgboost as xgb
import joblib
import matplotlib.pyplot as plt
from scipy.stats import pearsonr

# Paths
DATA_PATH    = r"D:\bot binance\Datasets\Base de Dados\all_data_enriched.csv"
OUTPUT_DIR   = r"D:\bot binance\Datasets\Modelo 4"
os.makedirs(OUTPUT_DIR, exist_ok=True)
LOG_PATH     = os.path.join(OUTPUT_DIR, "process.log")
SCATTER_PNG  = os.path.join(OUTPUT_DIR, "scatter_validation.png")
REG_MODEL    = os.path.join(OUTPUT_DIR, "xgb_reg.json")
CLF_MODEL    = os.path.join(OUTPUT_DIR, "xgb_clf_calib.pkl")
SCALER_MODEL = os.path.join(OUTPUT_DIR, "scaler.joblib")

# Sampling & thresholds
EXTREME_THRESHOLD = 0.02
EXTREME_FRAC      = 2.0
OTHER_FRAC        = 0.5
TARGET_MIN, TARGET_MAX = -0.1, 0.1
THRESHOLDS = np.linspace(0.3, 0.7, 41)

# HPO settings
SEARCH_ITERS = 25
PARAM_DIST = {
    'learning_rate': np.linspace(0.01, 0.2, 20),
    'max_depth': list(range(3, 11))
}


def setup_logging():
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    fmt = "%(asctime)s - %(levelname)s - %(message)s"
    ch = logging.StreamHandler()
    ch.setFormatter(logging.Formatter(fmt))
    logger.addHandler(ch)
    fh = logging.FileHandler(LOG_PATH, mode="w")
    fh.setFormatter(logging.Formatter(fmt))
    logger.addHandler(fh)


def direction_accuracy(y_true, y_pred):
    return np.mean(np.sign(y_pred) == np.sign(y_true))

if __name__ == "__main__":
    setup_logging()
    logging.info("Starting pipeline with HPO on classifier")

    # Load & features (abbreviated for brevity)
    df = pd.read_csv(
        DATA_PATH,
        sep=",",
        parse_dates=["open_time"],
        on_bad_lines="skip"
    )
    # ... datetime, filter, sampling, split ...
    # Prepare X_train_s, y_train_sign, X_val_s, y_val_sign as before

    # Hyperparameter search for XGBClassifier
    base_clf = XGBClassifier(
        objective="binary:logistic",
        subsample=0.8,
        colsample_bytree=0.8,
        n_estimators=200,
        use_label_encoder=False,
        verbosity=0
    )
    scorer = make_scorer(accuracy_score)
    search = RandomizedSearchCV(
        estimator=base_clf,
        param_distributions=PARAM_DIST,
        n_iter=SEARCH_ITERS,
        scoring=scorer,
        cv=3,
        random_state=42,
        n_jobs=-1
    )
    logging.info("Starting RandomizedSearchCV for classifier")
    search.fit(X_train_s, y_train_sign)
    best_params = search.best_params_
    logging.info("Best classifier params: %s", best_params)

    # Retrain with best params on full train set
    best_clf = XGBClassifier(
        **best_params,
        objective="binary:logistic",
        n_estimators=200,
        use_label_encoder=False,
        verbosity=0
    )
    best_clf.fit(X_train_s, y_train_sign)

    # Calibration
    clf_calib = CalibratedClassifierCV(estimator=best_clf, method="sigmoid", cv=3)
    clf_calib.fit(X_val_s, y_val_sign)
    joblib.dump(clf_calib, CLF_MODEL)

    # Evaluate threshold
    probs = clf_calib.predict_proba(X_val_s)[:,1]
    best_acc, best_thr = 0, 0.5
    for thr in THRESHOLDS:
        preds = (probs >= thr).astype(int)
        acc = accuracy_score(y_val_sign, preds)
        if acc > best_acc:
            best_acc, best_thr = acc, thr
    logging.info("Threshold search complete: best_thr=%.2f, best_acc=%.4f", best_thr, best_acc)

    # ... continue with regression and artifact saving as before ...
